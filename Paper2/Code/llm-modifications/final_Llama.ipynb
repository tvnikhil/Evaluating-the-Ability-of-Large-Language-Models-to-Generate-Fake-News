{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"21XXnNo44gd_","executionInfo":{"status":"ok","timestamp":1733431103115,"user_tz":360,"elapsed":15306,"user":{"displayName":"Research","userId":"04143786625875785090"}},"outputId":"a9a31851-dde4-44c0-e47a-4e9e5c039a3f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","id":"tFy3H3aPgx12","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733431136693,"user_tz":360,"elapsed":33585,"user":{"displayName":"Research","userId":"04143786625875785090"}},"outputId":"a0fd2167-f1ff-4729-a1dc-a9cbd319b65c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.9/389.9 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.5/90.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["! pip3 install --upgrade --quiet google-cloud-aiplatform[langchain] openai\n","! pip3 install --upgrade --quiet langchain-openai"]},{"cell_type":"code","execution_count":4,"metadata":{"cellView":"form","id":"XRvKdaPDTznN","executionInfo":{"status":"ok","timestamp":1733431136694,"user_tz":360,"elapsed":30,"user":{"displayName":"Research","userId":"04143786625875785090"}}},"outputs":[],"source":["import sys\n","\n","if \"google.colab\" in sys.modules:\n","\n","    import IPython\n","\n","    app = IPython.Application.instance()\n","    app.kernel.do_shutdown(True)"]},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","id":"NyKGtVQjgx13","executionInfo":{"status":"ok","timestamp":1733431324695,"user_tz":360,"elapsed":699,"user":{"displayName":"Research","userId":"04143786625875785090"}}},"outputs":[],"source":["import sys\n","\n","if \"google.colab\" in sys.modules:\n","\n","    from google.colab import auth\n","\n","    auth.authenticate_user()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Nqwi-5ufWp_B","executionInfo":{"status":"ok","timestamp":1733431325885,"user_tz":360,"elapsed":120,"user":{"displayName":"Research","userId":"04143786625875785090"}}},"outputs":[],"source":["PROJECT_ID = \"gen-lang-client-0539303742\"\n","\n","LOCATION = \"us-central1\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"MzGDU7TWdts_","executionInfo":{"status":"ok","timestamp":1733431330955,"user_tz":360,"elapsed":105,"user":{"displayName":"Research","userId":"04143786625875785090"}}},"outputs":[],"source":["BUCKET_NAME = \"ml_Llama\"\n","\n","BUCKET_URI = f\"gs://{BUCKET_NAME}\""]},{"cell_type":"code","execution_count":4,"metadata":{"cellView":"form","id":"B8DawN9D9NLU","executionInfo":{"status":"ok","timestamp":1733431334839,"user_tz":360,"elapsed":2694,"user":{"displayName":"Research","userId":"04143786625875785090"}}},"outputs":[],"source":["import vertexai\n","\n","vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"]},{"cell_type":"code","source":["pip install langchain_openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jXSXjwTPO2LK","executionInfo":{"status":"ok","timestamp":1733431339115,"user_tz":360,"elapsed":3325,"user":{"displayName":"Research","userId":"04143786625875785090"}},"outputId":"01026203-0a14-4293-cf43-9f69743e39dd"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.2.11)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.3.21)\n","Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.57.0)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.8.0)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (0.1.147)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (24.2)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (2.9.2)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (9.0.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (4.12.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.8.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.6)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain_openai) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain_openai) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain_openai) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain_openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain_openai) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"cellView":"form","id":"c1tEW-U968h8","executionInfo":{"status":"ok","timestamp":1733431345664,"user_tz":360,"elapsed":4586,"user":{"displayName":"Research","userId":"04143786625875785090"}}},"outputs":[],"source":["# Chat completions API\n","import openai\n","from google.auth import default, transport\n","from langchain import PromptTemplate\n","# Build\n","from langchain_openai import ChatOpenAI\n","from vertexai.preview import rag"]},{"cell_type":"code","execution_count":7,"metadata":{"cellView":"form","id":"i0qceuiQEPHv","executionInfo":{"status":"ok","timestamp":1733431354903,"user_tz":360,"elapsed":112,"user":{"displayName":"Research","userId":"04143786625875785090"}}},"outputs":[],"source":["def reAuth():\n","  credentials, _ = default()\n","  auth_request = transport.requests.Request()\n","  credentials.refresh(auth_request)\n","\n","  MODEL_LOCATION = \"us-central1\"\n","\n","  client = openai.OpenAI(\n","      base_url=f\"https://{MODEL_LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{MODEL_LOCATION}/endpoints/openapi/chat/completions?\",\n","      api_key=credentials.token,\n","  )\n","  return client"]},{"cell_type":"code","source":["client = reAuth()"],"metadata":{"id":"UTu4NFq1kak2","executionInfo":{"status":"ok","timestamp":1733431358795,"user_tz":360,"elapsed":327,"user":{"displayName":"Research","userId":"04143786625875785090"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"r7OhyH46H2H5","executionInfo":{"status":"ok","timestamp":1733431362545,"user_tz":360,"elapsed":143,"user":{"displayName":"Research","userId":"04143786625875785090"}}},"outputs":[],"source":["MODEL_ID = \"meta/llama-3.1-405b-instruct-maas\""]},{"cell_type":"code","execution_count":10,"metadata":{"id":"owv-5Sz5rIEU","executionInfo":{"status":"ok","timestamp":1733431363777,"user_tz":360,"elapsed":99,"user":{"displayName":"Research","userId":"04143786625875785090"}}},"outputs":[],"source":["temperature = 0.7\n","max_tokens = 8192\n","top_p = 0.85\n","stream = False"]},{"cell_type":"code","source":["pip install json-repair"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jko1H5SxE-V1","executionInfo":{"status":"ok","timestamp":1733431371481,"user_tz":360,"elapsed":3286,"user":{"displayName":"Research","userId":"04143786625875785090"}},"outputId":"85f573c6-6137-476f-a76d-6545331ec74e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting json-repair\n","  Downloading json_repair-0.30.3-py3-none-any.whl.metadata (11 kB)\n","Downloading json_repair-0.30.3-py3-none-any.whl (18 kB)\n","Installing collected packages: json-repair\n","Successfully installed json-repair-0.30.3\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","from json_repair import repair_json  # Ensure this library is installed\n","import time\n","\n","# Load the .tsv file\n","file_path = \"/content/drive/MyDrive/Final project/checkTest.tsv\"  # Replace with your file path\n","data = pd.read_csv(file_path, sep='\\t')\n","\n","# Ensure required columns are present\n","if 'clean_title' not in data.columns or '6_way_label' not in data.columns:\n","    raise ValueError(\"The input file must contain 'clean_title' and '6_way_label' columns.\")\n","\n","# Configuration\n","batch_size = 100 # Adjust the batch size as needed\n","start_batch = 12 # Specify the batch number to start from\n","OUTPUT_FILE = \"/content/drive/MyDrive/Final project/Llama_modified_data_max.json\"\n","FAILED_FILE = \"/content/drive/MyDrive/Final project/Llama_failed_batches_max.json\"\n","SAVE_INTERVAL = 5  # Save progress every 10 batches\n","flag = 0  # Reauthentication flag\n","\n","# Placeholder for system instruction\n","sysInstr = \"\"\"I will provide article titles in JSON format, each structured across multiple fields. Your task is to subtly modify the `clean_title` to retain its original intent and meaning while making the titles more challenging for fake news detection models, including BERT, CNN, Bi-LSTM, and SVM.\n","\n","**Modification Guidelines:**\n","- **Synonym Variation:** Replace words with less common synonyms or alternative expressions to alter surface-level patterns while preserving meaning.\n","- **Structural Changes:** Rephrase the title by altering the sentence structure (e.g., switching clauses or reordering phrases).\n","- **Contextual Nuance:** Introduce subtle hints of sarcasm, irony, or ambiguity to challenge the model's ability to infer context accurately.\n","- **Colloquial Language:** Use idiomatic expressions, informal phrases, or region-specific terms to increase linguistic variability.\n","- **Negation and Sentiment Shifts:** Add subtle negations, expressions of doubt, or shifts in sentiment to complicate sentiment analysis.\n","- **Noise Injection:** Incorporate harmless but unusual punctuation, slight spelling variations, or uncommon phrasing to disrupt token patterns.\n","\n","**Constraints:**\n","- Do not alter the category or core meaning of the title.\n","- The title must remain natural, plausible, and coherent, as it would appear in a reliable source.\n","- The modified titles should challenge model detection by leveraging long-range dependencies, local context changes, and subtle semantic shifts.\n","- Ensure the response is in valid JSON format, where each row includes `clean_title` and `label`.\n","- Avoid providing introductions, explanations, or extraneous text. Do not add unnecessary start or stop characters.\n","\n","Your modifications should aim to evade detection by exploiting weaknesses in the models' ability to process context, handle nuanced language, and recognize long-range dependencies.\"\"\"\n","try:\n","    with open(OUTPUT_FILE, \"r\") as json_file:\n","        modified_data = json.load(json_file)\n","except FileNotFoundError:\n","    modified_data = []\n","\n","try:\n","    with open(FAILED_FILE, \"r\") as failed_file:\n","        failed_batches = json.load(failed_file)\n","except FileNotFoundError:\n","    failed_batches = []\n","\n","# Batch processing loop\n","for iter, i in enumerate(range(start_batch * batch_size, len(data), batch_size), start=start_batch):\n","    batch_df = data.iloc[i : i + batch_size]  # Extract batch\n","    print(f\"Processing batch {iter + 1}/{(len(data) + batch_size - 1) // batch_size} (Rows {i} to {min(i + batch_size - 1, len(data) - 1)})...\")\n","\n","    # Convert the batch DataFrame to JSON\n","    batch_json = batch_df.to_json(orient=\"records\")\n","\n","    # Create prompt for the batch\n","    prompt = f\"\"\"\n","    Modify the content of the clean_title while keeping the 6_way_label unchanged.\n","    Articles (JSON):\n","    {batch_json}\n","    \"\"\"\n","    prompt = sysInstr + \"\\n\" + prompt\n","\n","    # Reauthenticate the client every 5 batches\n","    if flag == 3:\n","        client = reAuth()\n","        flag = 0\n","\n","    try:\n","        # Generate content using the pre-initialized client\n","        response = client.chat.completions.create(\n","            model=MODEL_ID,\n","            messages=[{\"role\": \"user\", \"content\": prompt}],\n","            temperature=temperature,\n","            max_tokens=max_tokens,\n","            top_p=top_p,\n","        )\n","        modified_text = response.choices[0].message.content\n","\n","        # Parse the modified JSON response\n","        json_objects = json.loads(modified_text)\n","\n","        # Process each object to sanitize the output\n","        sanitized_objects = []\n","        for original, modified in zip(batch_df.to_dict(orient=\"records\"), json_objects):\n","            sanitized_object = {\n","                \"clean_title\": modified.get(\"clean_title\", original[\"clean_title\"]).replace(\"_\", \" \"),  # Replace underscores\n","                \"6_way_label\": original[\"6_way_label\"]  # Preserve the original label\n","            }\n","            sanitized_objects.append(sanitized_object)\n","\n","        modified_data.extend(sanitized_objects)  # Add sanitized objects to the list\n","        print(f\"Batch {iter + 1} processed successfully!\")\n","\n","    except json.JSONDecodeError as e:\n","        print(f\"Error decoding JSON in batch {iter + 1}: {e}\")\n","\n","        # Attempt to repair the JSON if it's malformed\n","        repaired_text = repair_json(modified_text)\n","        if repaired_text:\n","            try:\n","                json_objects = json.loads(repaired_text)\n","\n","                # Process repaired JSON for sanitization\n","                sanitized_objects = []\n","                if isinstance(json_objects, list):  # Validate it's a list of dictionaries\n","                    for original, modified in zip(batch_df.to_dict(orient=\"records\"), json_objects):\n","                        sanitized_object = {\n","                            \"clean_title\": modified.get(\"clean_title\", original[\"clean_title\"]).replace(\"_\", \" \"),  # Replace underscores\n","                            \"6_way_label\": original[\"6_way_label\"]\n","                        }\n","                        sanitized_objects.append(sanitized_object)\n","                    modified_data.extend(sanitized_objects)\n","                    print(f\"Successfully repaired JSON for batch {iter + 1}.\")\n","                else:\n","                    raise ValueError(\"Repaired JSON is not a list of dictionaries.\")\n","            except Exception as validation_error:\n","                print(f\"Validation failed for repaired JSON in batch {iter + 1}: {validation_error}\")\n","                failed_batches.append({\"batch\": iter + 1, \"response\": repaired_text, \"prompt\": prompt})\n","        else:\n","            failed_batches.append({\"batch\": iter + 1, \"response\": modified_text, \"prompt\": prompt})\n","    except Exception as e:\n","        print(f\"Unexpected error in batch {iter + 1}: {e}\")\n","        failed_batches.append({\"batch\": iter + 1, \"response\": modified_text if 'modified_text' in locals() else None, \"prompt\": prompt})\n","\n","    flag += 1\n","\n","    # Save progress periodically\n","    if iter % SAVE_INTERVAL == 0:  # Save every 10 batches\n","        with open(OUTPUT_FILE, \"w\") as json_file:\n","            json.dump(modified_data, json_file, indent=4)\n","        with open(FAILED_FILE, \"w\") as failed_file:\n","            json.dump(failed_batches, failed_file, indent=4)\n","        print(f\"Intermediate data saved to {OUTPUT_FILE} and {FAILED_FILE}\")\n","\n","# Save the final modified data and failed batches\n","with open(OUTPUT_FILE, \"w\") as json_file:\n","    json.dump(modified_data, json_file, indent=4)\n","print(f\"Modified data saved to {OUTPUT_FILE}\")\n","\n","with open(FAILED_FILE, \"w\") as failed_file:\n","    json.dump(failed_batches, failed_file, indent=4)\n","print(f\"Failed batches saved to {FAILED_FILE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j5tA_g4GOc7q","outputId":"f8198eff-f701-47c9-fec9-ab311e87dbe4","executionInfo":{"status":"ok","timestamp":1733438896702,"user_tz":360,"elapsed":1194691,"user":{"displayName":"Research","userId":"04143786625875785090"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing batch 13/70 (Rows 1200 to 1299)...\n","Batch 13 processed successfully!\n","Processing batch 14/70 (Rows 1300 to 1399)...\n","Error decoding JSON in batch 14: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 14.\n","Processing batch 15/70 (Rows 1400 to 1499)...\n","Error decoding JSON in batch 15: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 15.\n","Processing batch 16/70 (Rows 1500 to 1599)...\n","Error decoding JSON in batch 16: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 16.\n","Intermediate data saved to /content/drive/MyDrive/Final project/Llama_modified_data_max.json and /content/drive/MyDrive/Final project/Llama_failed_batches_max.json\n","Processing batch 17/70 (Rows 1600 to 1699)...\n","Error decoding JSON in batch 17: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 17.\n","Processing batch 18/70 (Rows 1700 to 1799)...\n","Error decoding JSON in batch 18: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 18.\n","Processing batch 19/70 (Rows 1800 to 1899)...\n","Error decoding JSON in batch 19: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 19.\n","Processing batch 20/70 (Rows 1900 to 1999)...\n","Error decoding JSON in batch 20: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 20.\n","Processing batch 21/70 (Rows 2000 to 2099)...\n","Error decoding JSON in batch 21: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 21.\n","Intermediate data saved to /content/drive/MyDrive/Final project/Llama_modified_data_max.json and /content/drive/MyDrive/Final project/Llama_failed_batches_max.json\n","Processing batch 22/70 (Rows 2100 to 2199)...\n","Error decoding JSON in batch 22: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 22.\n","Processing batch 23/70 (Rows 2200 to 2299)...\n","Error decoding JSON in batch 23: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 23.\n","Processing batch 24/70 (Rows 2300 to 2399)...\n","Error decoding JSON in batch 24: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 24.\n","Processing batch 25/70 (Rows 2400 to 2499)...\n","Error decoding JSON in batch 25: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 25.\n","Processing batch 26/70 (Rows 2500 to 2599)...\n","Error decoding JSON in batch 26: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 26.\n","Intermediate data saved to /content/drive/MyDrive/Final project/Llama_modified_data_max.json and /content/drive/MyDrive/Final project/Llama_failed_batches_max.json\n","Processing batch 27/70 (Rows 2600 to 2699)...\n","Batch 27 processed successfully!\n","Processing batch 28/70 (Rows 2700 to 2799)...\n","Error decoding JSON in batch 28: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 28.\n","Processing batch 29/70 (Rows 2800 to 2899)...\n","Error decoding JSON in batch 29: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 29.\n","Processing batch 30/70 (Rows 2900 to 2999)...\n","Error decoding JSON in batch 30: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 30.\n","Processing batch 31/70 (Rows 3000 to 3099)...\n","Error decoding JSON in batch 31: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 31.\n","Intermediate data saved to /content/drive/MyDrive/Final project/Llama_modified_data_max.json and /content/drive/MyDrive/Final project/Llama_failed_batches_max.json\n","Processing batch 32/70 (Rows 3100 to 3199)...\n","Error decoding JSON in batch 32: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 32.\n","Processing batch 33/70 (Rows 3200 to 3299)...\n","Error decoding JSON in batch 33: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 33.\n","Processing batch 34/70 (Rows 3300 to 3399)...\n","Error decoding JSON in batch 34: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 34.\n","Processing batch 35/70 (Rows 3400 to 3499)...\n","Error decoding JSON in batch 35: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 35.\n","Processing batch 36/70 (Rows 3500 to 3599)...\n","Error decoding JSON in batch 36: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 36.\n","Intermediate data saved to /content/drive/MyDrive/Final project/Llama_modified_data_max.json and /content/drive/MyDrive/Final project/Llama_failed_batches_max.json\n","Processing batch 37/70 (Rows 3600 to 3699)...\n","Error decoding JSON in batch 37: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 37.\n","Processing batch 38/70 (Rows 3700 to 3799)...\n","Error decoding JSON in batch 38: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 38.\n","Processing batch 39/70 (Rows 3800 to 3899)...\n","Error decoding JSON in batch 39: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 39.\n","Processing batch 40/70 (Rows 3900 to 3999)...\n","Error decoding JSON in batch 40: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 40.\n","Processing batch 41/70 (Rows 4000 to 4099)...\n","Error decoding JSON in batch 41: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 41.\n","Intermediate data saved to /content/drive/MyDrive/Final project/Llama_modified_data_max.json and /content/drive/MyDrive/Final project/Llama_failed_batches_max.json\n","Processing batch 42/70 (Rows 4100 to 4199)...\n","Error decoding JSON in batch 42: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 42.\n","Processing batch 43/70 (Rows 4200 to 4299)...\n","Error decoding JSON in batch 43: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 43.\n","Processing batch 44/70 (Rows 4300 to 4399)...\n","Error decoding JSON in batch 44: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 44.\n","Processing batch 45/70 (Rows 4400 to 4499)...\n","Error decoding JSON in batch 45: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 45.\n","Processing batch 46/70 (Rows 4500 to 4599)...\n","Error decoding JSON in batch 46: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 46.\n","Intermediate data saved to /content/drive/MyDrive/Final project/Llama_modified_data_max.json and /content/drive/MyDrive/Final project/Llama_failed_batches_max.json\n","Processing batch 47/70 (Rows 4600 to 4699)...\n","Error decoding JSON in batch 47: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 47.\n","Processing batch 48/70 (Rows 4700 to 4799)...\n","Error decoding JSON in batch 48: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 48.\n","Processing batch 49/70 (Rows 4800 to 4899)...\n","Error decoding JSON in batch 49: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 49.\n","Processing batch 50/70 (Rows 4900 to 4999)...\n","Batch 50 processed successfully!\n","Processing batch 51/70 (Rows 5000 to 5099)...\n","Error decoding JSON in batch 51: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 51.\n","Intermediate data saved to /content/drive/MyDrive/Final project/Llama_modified_data_max.json and /content/drive/MyDrive/Final project/Llama_failed_batches_max.json\n","Processing batch 52/70 (Rows 5100 to 5199)...\n","Error decoding JSON in batch 52: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 52.\n","Processing batch 53/70 (Rows 5200 to 5299)...\n","Error decoding JSON in batch 53: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 53.\n","Processing batch 54/70 (Rows 5300 to 5399)...\n","Error decoding JSON in batch 54: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 54.\n","Processing batch 55/70 (Rows 5400 to 5499)...\n","Error decoding JSON in batch 55: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 55.\n","Processing batch 56/70 (Rows 5500 to 5599)...\n","Error decoding JSON in batch 56: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 56.\n","Intermediate data saved to /content/drive/MyDrive/Final project/Llama_modified_data_max.json and /content/drive/MyDrive/Final project/Llama_failed_batches_max.json\n","Processing batch 57/70 (Rows 5600 to 5699)...\n","Error decoding JSON in batch 57: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 57.\n","Processing batch 58/70 (Rows 5700 to 5799)...\n","Error decoding JSON in batch 58: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 58.\n","Processing batch 59/70 (Rows 5800 to 5899)...\n","Error decoding JSON in batch 59: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 59.\n","Processing batch 60/70 (Rows 5900 to 5999)...\n","Error decoding JSON in batch 60: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 60.\n","Processing batch 61/70 (Rows 6000 to 6099)...\n","Error decoding JSON in batch 61: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 61.\n","Intermediate data saved to /content/drive/MyDrive/Final project/Llama_modified_data_max.json and /content/drive/MyDrive/Final project/Llama_failed_batches_max.json\n","Processing batch 62/70 (Rows 6100 to 6199)...\n","Batch 62 processed successfully!\n","Processing batch 63/70 (Rows 6200 to 6299)...\n","Error decoding JSON in batch 63: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 63.\n","Processing batch 64/70 (Rows 6300 to 6399)...\n","Error decoding JSON in batch 64: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 64.\n","Processing batch 65/70 (Rows 6400 to 6499)...\n","Batch 65 processed successfully!\n","Processing batch 66/70 (Rows 6500 to 6599)...\n","Error decoding JSON in batch 66: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 66.\n","Intermediate data saved to /content/drive/MyDrive/Final project/Llama_modified_data_max.json and /content/drive/MyDrive/Final project/Llama_failed_batches_max.json\n","Processing batch 67/70 (Rows 6600 to 6699)...\n","Error decoding JSON in batch 67: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 67.\n","Processing batch 68/70 (Rows 6700 to 6799)...\n","Error decoding JSON in batch 68: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 68.\n","Processing batch 69/70 (Rows 6800 to 6899)...\n","Error decoding JSON in batch 69: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 69.\n","Processing batch 70/70 (Rows 6900 to 6992)...\n","Error decoding JSON in batch 70: Expecting value: line 1 column 1 (char 0)\n","Successfully repaired JSON for batch 70.\n","Modified data saved to /content/drive/MyDrive/Final project/Llama_modified_data_max.json\n","Failed batches saved to /content/drive/MyDrive/Final project/Llama_failed_batches_max.json\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1BGhUyqCWd6I8fh7iPo3RfYHQcuilnvuy","timestamp":1731864293306},{"file_id":"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_openai_api_llama3_1.ipynb","timestamp":1731804058790}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}